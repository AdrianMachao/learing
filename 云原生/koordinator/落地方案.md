# 混部方案
针对当前业务，确定具体接入方案

# 应用等级划分
LSE：支付级别（重宝A类）
LSR：一般重要应用（B类）
LS：电商新消费类（C类）
BE：离线业务

# Qos

# Suppress
目前看好像主要是CPU压制

# Evict


# 大数据接入方案
大数据接入方案，需要主要大数据业务的一些特点，例如shuffle
## yarn on k8s
参考社区即可，k8s、yarn双调度器并存
### 技术方案
按照开源社区适配操作即可
此方案时会将原有大数据机器合并到一个集群中，原有大数据保持接入方式不变

## spark operator && flink operator
对于一些operator模式接入的引擎，可采用联邦集群模式调度，将任务分发到子集群中
### 技术方案
![spark-operator-multi-cluster](./images/spark-operator-multi-cluster.svg)
基于当前多集群资源调度，需要一些适配操作。
#### sparkApplication
```
apiVersion: sparkoperator.k8s.io/v1beta2
kind: SparkApplication
metadata:
  name: spark-pi
  namespace: default     # 需要确保命名空间在spark.jobNamespaces指定的命名空间列表中。
spec:
  type: Scala
  mode: cluster
  image: registry-cn-hangzhou.ack.aliyuncs.com/ack-demo/spark:3.5.4
  imagePullPolicy: IfNotPresent
  mainClass: org.apache.spark.examples.SparkPi
  mainApplicationFile: local:///opt/spark/examples/jars/spark-examples_2.12-3.5.4.jar
  arguments:
  - "1000"
  sparkVersion: 3.5.4
  driver:
    cores: 1
    memory: 512m
    priorityClassName: low-priority
    serviceAccount: spark-operator-spark   # 如果您自定义了ServiceAccount名称，则需要进行相应修改。
  executor:
    instances: 1
    cores: 1
    memory: 512m
    priorityClassName: low-priority
  restartPolicy:
    type: Never
```
### 适配
1. batch资源同步
2. webhook机制，修改SparkApplication申请资源为batch资源
3. gang调度，需要修改为SparkApplication模板，适配不同调度器即可
4. 调度策略（租户配额等，可参考vocalno-global）

# AI接入方案
AI业务中一些训练任务能否混部，也是可以的，但需要做好checkpoint，不然被中断后又要重新训练
## 技术方案
相对大数据接入方案简单一点，相关训练框架都已operator化，按照联邦调度方案接入即可
PytorchJob
```
```

## 资源同步申请
1. batch资源同步、GPU资源同步
2. webhook机制，修改PytorchJob申请资源为batch资源

## 调度策略
1. gang调度，需要修改为PytorchJob模板，适配不同调度器即可
2. 调度策略（租户配额等，可参考vocalno-global）
3. GPU等device调度